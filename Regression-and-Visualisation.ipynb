{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note for Class:</b> You can enable the table of content using an add-in which can be installed by copying the following lines of code and pasting them into the terminal.  \n",
    "    \n",
    "`jupyter nbextension install --user https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.js`\n",
    "\n",
    "`curl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.css > $(jupyter --data-dir)/nbextensions/toc.css`\n",
    "\n",
    "`jupyter nbextension enable toc`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Visualisation\n",
    "## Learning Goals\n",
    "\n",
    "- Learn to fit regression model in Python\n",
    "- Learn to visualise your results\n",
    "\n",
    "### Import packages and data\n",
    "In this example, we use an inbuilt dataset \"diabetes\" in the sklearn package.\n",
    "For more information regarding the features (the $X$) and the target (the $y$), please refer to the sklearn documentation: \n",
    "\n",
    "https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset\n",
    "\n",
    "The sklearn pacakge offers a basket of simple and efficient tools for data mining and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "print('# of observations (N) and # of each observation\\'s attributes (p) are',diabetes.data.shape)\n",
    "print('# of responses (N) is',diabetes.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the data\n",
    "\n",
    "There are 10 attributes in the data set. To visualize the relationship, we draw a scatter plot for each attribute `x` against the dependent variable `y` (a quantitative measure of disease progression one year after baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Age','Sex','Body mass index','Average blood pressure','S1','S2','S3','S4','S5','S6']\n",
    "y = diabetes.target\n",
    "X = diabetes.data\n",
    "for i in range(10):\n",
    "    x = X[:,i]\n",
    "    plt.scatter(x,y, color = 'b')\n",
    "    plt.title(column_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data set into training and testing data\n",
    "\n",
    "Using the function `train_test_split`, we split our data set so that $10\\%$ data is in the testing set and $90\\%$ data is in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Linear Regression\n",
    "\n",
    "We have imported the `LinearRegression` class in the code above. Now we need to create an object of that class, which is the linear regression model. \n",
    "\n",
    "Then we will use the fit method to 'fit' the model to our dataset, i.e. we make the regressor study our data and learn from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time we are interested in the coefficients and the intercept of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coefficients of the model:',lr.coef_)\n",
    "print ('Intercept of the model:',lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since least squares estimation has a nice analytical form, we can verify our findings.\n",
    "\n",
    "Stack a column of ones in our training $X$ and call it matrix $A$, then we can apply the formula $\\hat{\\beta} = A^{\\dagger} y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.column_stack([np.ones(len(x_train)), x_train])\n",
    "LS_coef = np.linalg.pinv(A)@y_train\n",
    "print (LS_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model, we can test the model with our testing dataset. We will create predictions $\\hat{y}$ using $X$ in the testing data and compare the prediction $\\hat{y}$ to the $y$ in the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr.predict(x_test)\n",
    "\n",
    "# Calaulate the RMS, given observed value y and estimated value y_hat\n",
    "def RMSE(y,y_hat):\n",
    "    return np.linalg.norm(y-y_hat)/len(y)**0.5\n",
    "\n",
    "print (\"Testing Error: \", RMSE(y_test,y_hat))\n",
    "print (\"Training Error: \", RMSE(y_train, lr.predict(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Inferences\n",
    "\n",
    "We can also obtain the details regarding statistical significance of our model using the package `statsmodels`.\n",
    "\n",
    "The statsmodel is a Python package providing tools for the estimation of many different statistical models, as well as for conducting statistical tests. The online documentation is hosted at www.statsmodels.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(x_train)\n",
    "est = sm.OLS(y_train, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on plots\n",
    "\n",
    "We will now demonstrate more on plots using another famous dataset: Iris data set.\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/index.html#iris-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "column_names = ['sepal length','sepal width','petal length','petal width']\n",
    "print (X.shape)\n",
    "print (Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plots\n",
    "Let's do a scatter plot on the sepal width against the sepal length. To give the graph more meaning, we can color each data point by its class. This can be done by creating a dictionary which maps from class to color and then scattering each point on its own using a for-loop and passing the respective color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create color dictionary\n",
    "colors = {0:'r',1:'g',2:'b'}\n",
    "# plot each data-point\n",
    "for i in range(len(Y)):\n",
    "    plt.scatter(X[i][0], X[i][1], color=colors[Y[i]])\n",
    "# set a title and labels\n",
    "plt.title('Iris Dataset')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('sepal_width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram\n",
    "In matplotlib we can create a histogram using the `hist` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diabetes.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute multiple graphs, we can use `subplots`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t):\n",
    "    return np.exp(-t) * np.cos(2*np.pi*t)\n",
    "\n",
    "t1 = np.arange(0.0, 5.0, 0.1)\n",
    "t2 = np.arange(0.0, 5.0, 0.01)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(t1, f(t1), color='blue', marker='o')\n",
    "plt.plot(t2, f(t2), color='black')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t2, np.cos(2*np.pi*t2), color='orange', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "X = pd.DataFrame(X)\n",
    "sns.pairplot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
